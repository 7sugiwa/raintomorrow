{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Milestone 2: Australian Weather Prediction for Agricultural Optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Farhan Falahaqil Rafi\n",
    "\n",
    "FTDS-003-BSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background:\n",
    "Australia's diverse climate ranges from tropical in the north to temperate in the south. The agricultural sector is significantly affected by the weather conditions, especially concerning temperature, rainfall, and humidity. Reliable predictions of weather conditions are crucial for farmers to plan sowing, irrigation, and harvesting activities. The recent unpredictable weather patterns due to climate change have increased the demand for more accurate and localized weather forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Objective:\n",
    "The main objective of this project is to develop a Machine Learning model that can predict weather conditions, specifically rainfall, in various locations across Australia. The predictions will help farmers and agricultural businesses in decision-making processes, optimizing crop yield, and minimizing losses due to unforeseen adverse weather conditions. By providing an accurate forecast, the model aims to contribute towards a more sustainable and efficient agricultural sector in Australia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview:\n",
    "The dataset chosen for this project is the 'weatherAUS.csv', which contains about 10 years of daily weather observations from numerous Australian weather stations. The dataset includes various features such as date, location, temperature, humidity, pressure, wind speed, and more, along with the target variable 'RainTomorrow', indicating if it rained the next day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach:\n",
    "The project will involve several stages, starting with exploratory data analysis to understand the patterns and characteristics of the weather data. Following this, feature engineering will be conducted to prepare the data for modeling. Several Supervised Learning models will be experimented with, including but not limited to Decision Trees, Random Forest, and Gradient Boosting, to predict the likelihood of rain. The models' performances will be compared based on appropriate metrics, and the best performing model will be optimized further through hyperparameter tuning. Finally, the chosen model will be deployed to provide easy access for end-users, primarily farmers and agricultural planners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Impact:\n",
    "The successful completion of this project is expected to provide a robust tool for accurate weather prediction, thereby aiding the agricultural sector in better planning and resource allocation. This will not only increase efficiency and yield but also contribute to the economic stability of the agricultural community and related industries in Australia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Analysis and Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import phik\n",
    "\n",
    "# Preprocessing and Feature Engineering Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Machine Learning Model Libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Model Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Handling Imbalanced Dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Pipeline Libraries\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Model Persistence\n",
    "import pickle\n",
    "\n",
    "# Miscellaneous Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Loading**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('weatherAUS.csv')\n",
    "\n",
    "# display the first few rows of the dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the size of the dataset\n",
    "print(\"\\nSize of the dataset (rows, columns):\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 145,460 entries and 23 columns. Each entry corresponds to daily weather observations at various locations across Australia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a concise summary of the dataframe, including the number of non-null values in each column\n",
    "print(\"\\nDataframe information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Entries and Columns**: The dataframe consists of 145,460 entries and 23 features.\n",
    "- **Feature Types**: The features are a mix of numerical (float64) and categorical (object) types.\n",
    "- **Non-Null Counts**: Some columns have missing values; for instance, 'Sunshine' and 'Evaporation' have a significant number of missing entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Summary of Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display statistical summary of numerical features\n",
    "print(\"\\nStatistical Summary of Numerical Features:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The statistical summary includes count, mean, standard deviation, minimum, 25th percentile, median, 75th percentile, and maximum for numerical features.\n",
    "- Notable observations include the range of temperatures, rainfall, and wind speed, indicating the climate's variability across different regions and timeframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the presence of null values\n",
    "print(\"\\nChecking for null values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Null value counts in each column indicate missing data. For example, 'Evaporation' and 'Sunshine' have the highest number of missing values, followed by 'Cloud9am' and 'Cloud3pm'.\n",
    "- Handling these missing values will be a crucial step in the data preprocessing stage to ensure the quality of our machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Values in 'RainTomorrow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the unique values in 'RainTomorrow', our target variable\n",
    "print(\"\\nUnique values in 'RainTomorrow':\")\n",
    "print(df['RainTomorrow'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The target variable 'RainTomorrow' indicates if it rained the next day with 'Yes', 'No', or nan (missing value).\n",
    "- Understanding the distribution of this variable is essential for predicting rainfall and evaluating model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the aesthetic style of the plots\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# plot distribution for each feature in the dataset\n",
    "for column in df.columns:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    if len(df[column].unique()) > 10:\n",
    "        sns.histplot(df[column], kde=True, color='skyblue')\n",
    "        plt.title(f'Distribution of {column}')\n",
    "    else:\n",
    "        sns.countplot(x=column, data=df, palette='Set2')\n",
    "        plt.title(f'Count of different classes in {column}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In examining the distribution plots for our key weather variables, I've noticed several interesting patterns:\n",
    "\n",
    "- **MinTemp (Minimum Temperature)**: The distribution is approximately normal but leans a bit towards the cooler side. This makes sense as it reflects a range of minimum temperatures, with a majority clustering near the average value.\n",
    "\n",
    "- **MaxTemp (Maximum Temperature)**: Similar to MinTemp, this graph is also somewhat bell-shaped but tilts towards warmer temperatures. It's a clear indication of the diverse range of maximum temperatures we see, which is expected given Australia's varied climate.\n",
    "\n",
    "- **Rainfall**: This one's intriguing as it's heavily skewed to the left. It looks like days with little to no rainfall are far more common than days with heavy rainfall, which suggests that high rainfall is an exception rather than the norm.\n",
    "\n",
    "- **Humidity9am**: Here, we see a slight skew to the left, pointing out that higher humidity levels in the morning are more frequently observed.\n",
    "\n",
    "- **Humidity3pm**: The afternoon humidity tells a different story. The spread is wider, showing more variability in humidity levels later in the day, with a tendency towards drier conditions.\n",
    "\n",
    "- **Pressure9am and Pressure3pm**: Both these variables exhibit bell-shaped distributions and are centered around similar ranges, indicative of relatively stable atmospheric pressure with minor fluctuations.\n",
    "\n",
    "- **WindGustSpeed**: This plot is right-skewed, which tells me that days with lower wind gust speeds are much more common, but there are occasional instances of significantly higher speeds.\n",
    "\n",
    "Through these distributions, I'm getting a clearer picture of our weather patterns. For instance, the skewness in the Rainfall data highlights the rarity of heavy rainfall, while the temperature and pressure distributions suggest a more consistent range of values. This analysis is laying a solid foundation for understanding the climatic behaviors in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the phi_k correlation matrix\n",
    "phi_k_correlation = df.phik_matrix()\n",
    "\n",
    "# setting up the matplotlib figure\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# drawing the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(phi_k_correlation, annot=True, fmt=\".2f\", linewidths=.5, cmap='coolwarm')\n",
    "\n",
    "# adding the title\n",
    "plt.title('Phi_k Correlation Matrix Heatmap')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the correlation matrix of our dataset has revealed several interesting relationships between different weather variables, which are crucial for understanding the dynamics of weather patterns in Australia.\n",
    "\n",
    "- **Temperature Variables (MinTemp, MaxTemp, Temp9am, Temp3pm)**: These variables show a strong positive correlation with each other. This is expected as they are all measures of temperature at different times of the day. The high correlation between MaxTemp and Temp3pm (0.99) is particularly notable, suggesting that the maximum temperature of the day is a good predictor of the temperature in the late afternoon.\n",
    "\n",
    "- **Humidity Variables (Humidity9am, Humidity3pm)**: There's a significant positive correlation between morning and afternoon humidity levels. However, Humidity3pm shows a stronger correlation with RainTomorrow (0.64) compared to Humidity9am (0.35), indicating that afternoon humidity levels might be a more critical predictor for rain the next day.\n",
    "\n",
    "- **Pressure Variables (Pressure9am, Pressure3pm)**: These two exhibit a very high positive correlation, which is logical given they represent atmospheric pressure at different times of the day. Both these variables also show a moderate negative correlation with temperature variables, highlighting the inverse relationship between atmospheric pressure and temperature.\n",
    "\n",
    "- **Wind Variables (WindGustSpeed, WindSpeed9am, WindSpeed3pm)**: WindGustSpeed shows a significant positive correlation with both WindSpeed9am and WindSpeed3pm. This indicates that higher gust speeds are generally accompanied by higher wind speeds throughout the day.\n",
    "\n",
    "- **Sunshine**: Sunshine shows a strong negative correlation with Cloud9am and Cloud3pm, which is expected as more clouds mean less sunshine. Interestingly, Sunshine also has a significant negative correlation with RainTomorrow (-0.58), suggesting that less sunny days have a higher likelihood of rain the next day.\n",
    "\n",
    "- **Cloud Variables (Cloud9am, Cloud3pm)**: These two variables are strongly correlated, indicating that cloud cover tends to be consistent throughout the day. Both variables also show a positive correlation with RainTomorrow, with Cloud3pm having a slightly stronger relationship.\n",
    "\n",
    "Focusing on the target variable, ***'RainTomorrow'***, the correlation analysis provides crucial insights into how various weather features might influence the likelihood of rain the following day. Here's a detailed interpretation:\n",
    "\n",
    "1. **Temperature Variables (MinTemp, MaxTemp, Temp9am, Temp3pm)**: \n",
    "   - These show a negative correlation with 'RainTomorrow', particularly Temp3pm (correlation: -0.26). This suggests that higher temperatures during the day might be associated with a lower likelihood of rain the next day. \n",
    "\n",
    "2. **Rainfall & RainToday**: \n",
    "   - Both 'Rainfall' and 'RainToday' exhibit a positive correlation with 'RainTomorrow' (correlations: 0.12 and 0.47, respectively). This indicates that days following rainfall, or days classified as 'RainToday', have a higher probability of experiencing rain.\n",
    "\n",
    "3. **Humidity Variables (Humidity9am, Humidity3pm)**: \n",
    "   - Humidity, especially in the afternoon (Humidity3pm), shows a strong positive correlation with 'RainTomorrow' (correlation: 0.64). This highlights humidity's role as a significant predictor, where higher humidity levels might increase the chances of rain the next day.\n",
    "\n",
    "4. **Pressure Variables (Pressure9am, Pressure3pm)**: \n",
    "   - Both morning and afternoon pressures exhibit a negative correlation with 'RainTomorrow' (correlations: -0.33 and -0.31, respectively), suggesting that higher atmospheric pressure could be associated with lower chances of rain.\n",
    "\n",
    "5. **Wind Variables (WindGustSpeed, WindSpeed9am, WindSpeed3pm)**: \n",
    "   - WindGustSpeed shows a modest positive correlation with 'RainTomorrow' (correlation: 0.31), indicating that days with stronger wind gusts might have a slightly increased likelihood of rain.\n",
    "\n",
    "6. **Sunshine**: \n",
    "   - Sunshine has a notable negative correlation with 'RainTomorrow' (correlation: -0.58), implying that fewer hours of sunshine are associated with a higher likelihood of rain the following day.\n",
    "\n",
    "7. **Cloud Variables (Cloud9am, Cloud3pm)**: \n",
    "   - Both Cloud9am and Cloud3pm show positive correlations with 'RainTomorrow' (correlations: 0.42 and 0.52, respectively), with Cloud3pm being more strongly correlated. This suggests that increased cloud cover might be a good predictor of rain.\n",
    "\n",
    "8. **Evaporation**: \n",
    "   - Evaporation has a low negative correlation with 'RainTomorrow' (correlation: -0.04), indicating it might not be a strong predictor for rain.\n",
    "\n",
    "In summary, the correlation analysis, especially with respect to 'RainTomorrow', has highlighted the critical importance of specific weather features in predicting rainfall. Key variables such as Humidity3pm, Cloud3pm, Sunshine, and RainToday demonstrate significant correlations with the likelihood of rain on the following day. These findings, coupled with the strong interrelationships observed among temperature, humidity, pressure, and cloud cover variables, provide a comprehensive understanding of the factors influencing rainfall. This comprehensive correlation insight is not only vital in identifying pivotal roles these variables play in our predictive modeling but also instrumental in guiding the feature selection and engineering process. Such an understanding is crucial for developing an effective model to accurately predict rain occurrences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to datetime format and extract year and month for trend analysis\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating annual and monthly averages for key variables\n",
    "annual_trends = df.groupby('Year')[['MinTemp', 'MaxTemp', 'Rainfall', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm']].mean()\n",
    "monthly_trends = df.groupby('Month')[['MinTemp', 'MaxTemp', 'Rainfall', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying annual trends\n",
    "annual_trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying monthly trends\n",
    "monthly_trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure and axes for subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))\n",
    "\n",
    "# Plotting annual trends\n",
    "annual_trends[['MinTemp', 'MaxTemp']].plot(ax=axes[0,0], title='Annual Avg Temperature')\n",
    "annual_trends['Rainfall'].plot(ax=axes[0,1], title='Annual Avg Rainfall')\n",
    "annual_trends[['Humidity9am', 'Humidity3pm']].plot(ax=axes[0,2], title='Annual Avg Humidity')\n",
    "annual_trends[['Pressure9am', 'Pressure3pm']].plot(ax=axes[0,3], title='Annual Avg Pressure')\n",
    "\n",
    "# Plotting monthly trends\n",
    "monthly_trends[['MinTemp', 'MaxTemp']].plot(ax=axes[1,0], title='Monthly Avg Temperature')\n",
    "monthly_trends['Rainfall'].plot(ax=axes[1,1], title='Monthly Avg Rainfall')\n",
    "monthly_trends[['Humidity9am', 'Humidity3pm']].plot(ax=axes[1,2], title='Monthly Avg Humidity')\n",
    "monthly_trends[['Pressure9am', 'Pressure3pm']].plot(ax=axes[1,3], title='Monthly Avg Pressure')\n",
    "\n",
    "# Enhancing layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflecting on the annual and monthly trends in our weather dataset, here are my observations:\n",
    "\n",
    "**Annual Trends:**\n",
    "- **Temperature (MinTemp and MaxTemp)**: Reviewing both minimum and maximum temperatures over the years, I noticed some fluctuation. However, there's no evident long-term trend indicating a gradual increase or decrease in temperatures throughout the dataset's timeframe.\n",
    "  \n",
    "- **Rainfall**: The annual rainfall data also presented variations from year to year. While some years showed higher average rainfall, there wasn't a clear, consistent trend of increasing or decreasing rainfall over the years.\n",
    "\n",
    "- **Humidity (Morning and Afternoon)**: Analyzing humidity levels for both morning and afternoon, I observed yearly variances. Yet, similar to temperature and rainfall, there wasn't an apparent trend that pointed to a gradual increase or decrease in humidity levels over the years.\n",
    "\n",
    "- **Pressure (Morning and Afternoon)**: The atmospheric pressure readings, both in the morning and afternoon, exhibited some yearly fluctuations. However, these readings remained relatively consistent, showing no significant long-term changes.\n",
    "\n",
    "**Monthly Trends:**\n",
    "- **Temperature**: The monthly temperature data clearly reflected the seasonal cycle, with higher temperatures during the warmer months and lower during the cooler months. This pattern was consistently observed each year, aligning with the expected seasonal shifts.\n",
    "\n",
    "- **Rainfall**: Rainfall also showed a distinct seasonal pattern. Certain months consistently experienced more rainfall, indicating a variation between wet and dry seasons throughout the year.\n",
    "\n",
    "- **Humidity**: Like temperature and rainfall, humidity levels also exhibited seasonal variations. Some months consistently showed higher or lower humidity.\n",
    "\n",
    "- **Pressure**: The atmospheric pressure varied across different months, displaying a pattern possibly linked to the seasonal changes observed in temperature and rainfall.\n",
    "\n",
    "In conclusion, while annual trends in temperature, rainfall, humidity, and pressure showed variability, they did not exhibit a clear long-term directional trend. On the other hand, the monthly trends for these variables strongly mirrored the expected seasonal patterns, reaffirming the influence of seasonal cycles on weather patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by location and calculating the mean for key variables\n",
    "location_based_analysis = df.groupby('Location')[['MinTemp', 'MaxTemp', 'Rainfall', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm']].mean()\n",
    "\n",
    "# Sorting the results for better readability\n",
    "location_based_analysis_sorted = location_based_analysis.sort_values(by=['Location'])\n",
    "\n",
    "location_based_analysis_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing regional weather data from the dataset, I've drawn several conclusions about the climatic patterns across different locations in Australia:\n",
    "\n",
    "1. **Temperature Variations (MinTemp and MaxTemp)**:\n",
    "   - Regions like Alice Springs and Katherine show higher average temperatures, indicative of warmer climates typically found in central and northern Australia.\n",
    "   - Conversely, locations like Mount Ginini and Canberra exhibit lower average temperatures, reflecting cooler climates often seen in southern regions.\n",
    "\n",
    "2. **Rainfall Patterns**:\n",
    "   - Coastal areas like Cairns, Coffs Harbour, and Sydney experience higher average rainfall, aligning with the typical wetter climates of coastal regions.\n",
    "   - Inland locations such as Woomera and Uluru register lower rainfall averages, which is consistent with the drier conditions usually found in central Australia.\n",
    "\n",
    "3. **Humidity Levels (Humidity9am and Humidity3pm)**:\n",
    "   - Coastal regions (e.g., Darwin, Wollongong) tend to exhibit higher humidity levels, both in the morning and afternoon, compared to inland areas like Alice Springs and Woomera where humidity levels are considerably lower.\n",
    "   - This pattern of higher humidity near the coast and lower humidity inland aligns well with the general climatic differences between these areas.\n",
    "\n",
    "4. **Atmospheric Pressure (Pressure9am and Pressure3pm)**:\n",
    "   - Pressure readings are fairly consistent across different locations, with slight variations. For instance, Darwin and Katherine, being coastal and northern, show slightly lower pressure values, which is typical for such regions.\n",
    "   - Inland areas like Alice Springs and Woomera tend to have slightly higher pressure readings on average, reflecting the atmospheric conditions of drier, inland locations.\n",
    "\n",
    "5. **Regional Variability**:\n",
    "   - Each region presents a unique combination of these weather elements, illustrating the diverse climatic conditions across Australia. For example, Darwin shows high temperatures and high rainfall, typical of a tropical climate, whereas Alice Springs exhibits high temperatures but low rainfall, characteristic of a desert climate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to map cities to their respective states or territories in Australia\n",
    "australian_cities_states = {\n",
    "    \"Adelaide\": \"South Australia\",\n",
    "    \"Albany\": \"Western Australia\",\n",
    "    \"Albury\": \"New South Wales\",\n",
    "    \"AliceSprings\": \"Northern Territory\",\n",
    "    \"BadgerysCreek\": \"New South Wales\",\n",
    "    \"Ballarat\": \"Victoria\",\n",
    "    \"Bendigo\": \"Victoria\",\n",
    "    \"Brisbane\": \"Queensland\",\n",
    "    \"Cairns\": \"Queensland\",\n",
    "    \"Canberra\": \"Australian Capital Territory\",\n",
    "    \"Cobar\": \"New South Wales\",\n",
    "    \"CoffsHarbour\": \"New South Wales\",\n",
    "    \"Dartmoor\": \"Victoria\",\n",
    "    \"Darwin\": \"Northern Territory\",\n",
    "    \"GoldCoast\": \"Queensland\",\n",
    "    \"Hobart\": \"Tasmania\",\n",
    "    \"Katherine\": \"Northern Territory\",\n",
    "    \"Launceston\": \"Tasmania\",\n",
    "    \"Melbourne\": \"Victoria\",\n",
    "    \"MelbourneAirport\": \"Victoria\",\n",
    "    \"Mildura\": \"Victoria\",\n",
    "    \"Moree\": \"New South Wales\",\n",
    "    \"MountGambier\": \"South Australia\",\n",
    "    \"MountGinini\": \"Australian Capital Territory\",\n",
    "    \"Newcastle\": \"New South Wales\",\n",
    "    \"Nhil\": \"Victoria\",\n",
    "    \"NorahHead\": \"New South Wales\",\n",
    "    \"NorfolkIsland\": \"External Territory\",\n",
    "    \"Nuriootpa\": \"South Australia\",\n",
    "    \"PearceRAAF\": \"Western Australia\",\n",
    "    \"Penrith\": \"New South Wales\",\n",
    "    \"Perth\": \"Western Australia\",\n",
    "    \"PerthAirport\": \"Western Australia\",\n",
    "    \"Portland\": \"Victoria\",\n",
    "    \"Richmond\": \"New South Wales\",\n",
    "    \"Sale\": \"Victoria\",\n",
    "    \"SalmonGums\": \"Western Australia\",\n",
    "    \"Sydney\": \"New South Wales\",\n",
    "    \"SydneyAirport\": \"New South Wales\",\n",
    "    \"Townsville\": \"Queensland\",\n",
    "    \"Tuggeranong\": \"Australian Capital Territory\",\n",
    "    \"Uluru\": \"Northern Territory\",\n",
    "    \"WaggaWagga\": \"New South Wales\",\n",
    "    \"Walpole\": \"Western Australia\",\n",
    "    \"Watsonia\": \"Victoria\",\n",
    "    \"Williamtown\": \"New South Wales\",\n",
    "    \"Witchcliffe\": \"Western Australia\",\n",
    "    \"Wollongong\": \"New South Wales\",\n",
    "    \"Woomera\": \"South Australia\"\n",
    "}\n",
    "\n",
    "# Applying the provided mapping to the weather dfset to create a new column 'State'\n",
    "df['State'] = df['Location'].map(australian_cities_states)\n",
    "\n",
    "# Now let's perform the location-based analysis grouped by State this time\n",
    "state_based_analysis = df.groupby('State')[['MinTemp', 'MaxTemp', 'Rainfall', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm']].mean()\n",
    "\n",
    "state_based_analysis_sorted = state_based_analysis.sort_values(by='State')\n",
    "state_based_analysis_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the summarized weather data for different states and territories in Australia, we can draw some interesting conclusions about the climatic variations across the country:\n",
    "\n",
    "1. **Australian Capital Territory (ACT)**:\n",
    "   - Exhibits relatively cooler temperatures with an average MinTemp of 5.94°C and MaxTemp of 17.97°C.\n",
    "   - Rainfall is moderate, and humidity levels are comparatively higher, especially in the morning.\n",
    "\n",
    "2. **External Territory (Norfolk Island)**:\n",
    "   - Features a milder climate with an average MinTemp of 16.87°C and MaxTemp of 21.83°C.\n",
    "   - Higher rainfall and humidity, especially in the afternoon, reflecting its island geography.\n",
    "\n",
    "3. **New South Wales (NSW)**:\n",
    "   - Shows warmer temperatures (MinTemp: 12.96°C, MaxTemp: 23.87°C) and moderate rainfall.\n",
    "   - Humidity levels are moderate, with a notable decrease from morning to afternoon.\n",
    "\n",
    "4. **Northern Territory (NT)**:\n",
    "   - Has the warmest average temperatures among the states (MinTemp: 18.03°C, MaxTemp: 31.50°C), consistent with its tropical and desert regions.\n",
    "   - Lower humidity levels and a significant drop in atmospheric pressure, characteristic of arid, inland areas.\n",
    "\n",
    "5. **Queensland**:\n",
    "   - Warm and humid climate, with higher average temperatures (MinTemp: 18.83°C, MaxTemp: 27.77°C) and the highest rainfall among the states.\n",
    "   - High humidity levels, especially in the afternoon, typical of its tropical and subtropical climate.\n",
    "\n",
    "6. **South Australia**:\n",
    "   - Moderate temperatures (MinTemp: 11.05°C, MaxTemp: 22.75°C) with low rainfall.\n",
    "   - Lower humidity levels, particularly in the afternoon, indicating drier conditions.\n",
    "\n",
    "7. **Tasmania**:\n",
    "   - Cooler climate with lower average temperatures (MinTemp: 8.47°C, MaxTemp: 18.40°C).\n",
    "   - Moderate rainfall and higher humidity levels, reflecting its maritime climate.\n",
    "\n",
    "8. **Victoria**:\n",
    "   - Mild temperatures (MinTemp: 9.43°C, MaxTemp: 20.65°C) with moderate rainfall.\n",
    "   - Higher humidity, especially in the morning, indicative of its temperate climate.\n",
    "\n",
    "9. **Western Australia**:\n",
    "   - Diverse climatic conditions with warmer temperatures (MinTemp: 11.82°C, MaxTemp: 23.32°C) and moderate rainfall.\n",
    "   - Moderate humidity levels with a slight drop from morning to afternoon.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, comparing the weather data analysis using city-level granularity versus state-level aggregation reveals significant insights into the effectiveness of dimensionality reduction for this dataset. \n",
    "\n",
    "1. **City-Level Analysis**:\n",
    "   - Provides detailed, localized climatic information, capturing the unique microclimates and weather patterns specific to each city.\n",
    "   - Ideal for applications requiring high precision, such as urban planning, local agricultural strategies, and targeted weather forecasting.\n",
    "   - However, it involves handling a larger dataset with higher dimensionality, which can be more complex and computationally intensive.\n",
    "\n",
    "2. **State-Level Aggregation**:\n",
    "   - Offers a broader perspective, encapsulating the overall climate trends of an entire state or territory.\n",
    "   - Useful for macro-level planning and analysis, like statewide agricultural policies, tourism planning, and regional climate studies.\n",
    "   - Reduces the complexity and size of the dataset, simplifying the analysis and potentially enhancing the performance and interpretability of machine learning models.\n",
    "   - However, this approach may overlook local variations and microclimates within each state.\n",
    "\n",
    "In terms of dimensionality reduction, state-level aggregation is an effective method to streamline the dataset, making it more manageable and less resource-intensive to analyze. This approach can be particularly beneficial for machine learning models, as it reduces the risk of overfitting and improves computational efficiency. However, the choice between city-level detail and state-level aggregation should be guided by the specific requirements of the analysis or application in question. If the goal is to capture nuanced, local weather patterns, city-level data is more appropriate. Conversely, for broader, regional insights or when working with resource constraints, state-level aggregation offers a practical and efficient alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing a missing value analysis on the dataset\n",
    "\n",
    "# Calculating the total number of missing values for each column\n",
    "missing_values_total = df.isnull().sum()\n",
    "\n",
    "# Calculating the percentage of missing values for each column\n",
    "missing_values_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "# Combining both total and percentage of missing values into a single DataFrame for better presentation\n",
    "missing_values_analysis = pd.DataFrame({'Total Missing': missing_values_total, 'Percentage Missing': missing_values_percentage})\n",
    "\n",
    "missing_values_analysis.sort_values(by='Percentage Missing', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conducting a missing value analysis on the dataset, I've uncovered some key insights about the data gaps in various weather parameters, which are crucial for my understanding of the dataset's completeness:\n",
    "\n",
    "1. **Significant Gaps in Specific Parameters**:\n",
    "   - The data for 'Sunshine', 'Evaporation', 'Cloud3pm', and 'Cloud9am' show notably high percentages of missing entries. Particularly, 'Sunshine' tops the list with nearly half of its data missing. This highlights substantial gaps in these specific weather measurements.\n",
    "\n",
    "2. **Moderately Missing Data in Certain Features**:\n",
    "   - Atmospheric pressure readings for 9 am and 3 pm, along with wind-related parameters like 'WindDir9am', 'WindGustDir', and 'WindGustSpeed', exhibit around 7-10% missing data. This level of missingness is moderate and noteworthy.\n",
    "\n",
    "3. **Relatively Complete Core Temperature and Rainfall Data**:\n",
    "   - The core temperature readings ('MinTemp' and 'MaxTemp') and basic rainfall data have low missing values, under 3%. This lower rate indicates higher reliability and completeness for these fundamental weather measurements.\n",
    "\n",
    "4. **Implications for My Modeling Work**:\n",
    "   - The absence of data in crucial variables such as 'Sunshine' and 'Evaporation' could potentially limit the effectiveness of my predictive models, especially if these factors are significant predictors.\n",
    "\n",
    "5. **Reflections on Data Collection and Quality**:\n",
    "   - The pattern of missing data points towards possible issues in the data collection process, especially for parameters like 'Sunshine' and 'Evaporation'. This could be due to missing equipment or inconsistent recording practices in some recording stations.\n",
    "\n",
    "6. **Solid Foundation in Date and Location Data**:\n",
    "   - The absence of missing data in 'Date', 'Location', and 'State' is a positive aspect, ensuring a robust base for any time-series or location-based analyses I plan to conduct.\n",
    "\n",
    "In conclusion, this analysis of missing values is a critical step in preparing my dataset for more detailed analysis and modeling. It highlights the importance of carefully handling these gaps, perhaps through data imputation techniques or by considering the limitations they impose on my analysis. The strategy I choose to address these missing values will be pivotal and will depend on the specific needs of my analysis and the potential impact on the accuracy and reliability of my findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting key columns for outlier analysis\n",
    "key_columns = ['MinTemp', 'MaxTemp', 'Rainfall', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'WindGustSpeed']\n",
    "\n",
    "# Calculating the skewness for key numerical columns in the dataset\n",
    "skewness_analysis = df[key_columns].skew()\n",
    "\n",
    "skewness_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reviewing the skewness of key numerical columns in my dataset, I've made the following observations regarding the distribution of these weather parameters:\n",
    "\n",
    "1. **MinTemp**: The skewness is approximately 0.02, which suggests that the distribution of minimum temperatures is almost symmetric. This indicates a balanced spread of data on either side of the mean.\n",
    "\n",
    "2. **MaxTemp**: With a skewness of 0.22, the distribution of maximum temperatures is slightly right-skewed (positive skew). This implies a modest concentration of data below the mean, with a longer tail extending towards higher temperatures.\n",
    "\n",
    "3. **Rainfall**: The skewness value of 9.84 for rainfall indicates a highly right-skewed distribution. This is typical for rainfall data, where extreme values or heavy rainfall days are not uncommon.\n",
    "\n",
    "4. **Humidity9am**: A skewness of -0.48 reveals a slight left-skewed (negative skew) distribution. This means that morning humidity levels are generally high, with fewer instances of very low humidity.\n",
    "\n",
    "5. **Humidity3pm**: The skewness around 0.03 suggests a nearly symmetric distribution for afternoon humidity levels, similar to MinTemp.\n",
    "\n",
    "6. **Pressure9am and Pressure3pm**: Both these pressure readings show a slight left skew, with skewness values of -0.10 and -0.05, respectively. This indicates a slightly higher frequency of days with above-average atmospheric pressure.\n",
    "\n",
    "7. **WindGustSpeed**: Exhibiting a skewness of 0.87, the distribution is moderately right-skewed. This suggests that lower wind gust speeds are more common, but there are occasional days with significantly higher speeds.\n",
    "\n",
    "Based on this skewness analysis:\n",
    "\n",
    "- For nearly symmetric distributions like MinTemp, Humidity3pm, Pressure9am, and Pressure3pm, traditional methods such as the Interquartile Range (IQR) or Z-score are suitable for outlier detection.\n",
    "- For MaxTemp and WindGustSpeed, which show moderate skewness, I can still employ IQR or Z-score methods but should be mindful of the skewness potentially affecting the analysis.\n",
    "- Rainfall, being highly skewed, might require a data transformation approach (such as logarithmic transformation) before applying outlier detection methods. Alternatively, I could use non-parametric methods better suited for skewed distributions.\n",
    "- For Humidity9am, with its slight negative skew, methods like IQR or Z-score can be used, but it's important to consider the skewness in any analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing an outlier analysis on the dfset\n",
    "\n",
    "def detect_outliers(df, column):\n",
    "    # Calculating IQR\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Defining boundaries for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Identifying outliers\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "# Selecting key columns for outlier analysis\n",
    "normal_columns = ['MinTemp', 'MaxTemp', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'WindGustSpeed']\n",
    "\n",
    "# Applying outlier detection for each key column\n",
    "outlier_analysis = {}\n",
    "for col in normal_columns:\n",
    "    outlier_analysis[col] = {\n",
    "        \"Outliers\": detect_outliers(df, col).shape[0],\n",
    "        \"Percentage\": (detect_outliers(df, col).shape[0] / df.shape[0]) * 100\n",
    "    }\n",
    "\n",
    "outlier_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying a log transformation to the 'Rainfall' column\n",
    "# Adding a small constant to avoid log(0) which is undefined\n",
    "df['Rainfall_log'] = np.log(df['Rainfall'] + 1)  # Adding 1 to avoid log(0)\n",
    "\n",
    "# Plotting the original and transformed 'Rainfall' distributions for comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Original Rainfall distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['Rainfall'], bins=30, kde=True)\n",
    "plt.title('Original Rainfall Distribution')\n",
    "\n",
    "# Transformed (Log) Rainfall distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df['Rainfall_log'], bins=30, kde=True)\n",
    "plt.title('Log Transformed Rainfall Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculating outliers using IQR on the transformed Rainfall data\n",
    "Q1 = df['Rainfall_log'].quantile(0.25)\n",
    "Q3 = df['Rainfall_log'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Defining boundaries for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identifying outliers\n",
    "outliers_transformed = df[(df['Rainfall_log'] < lower_bound) | (df['Rainfall_log'] > upper_bound)]\n",
    "\n",
    "# Number of outliers in the transformed df\n",
    "num_outliers_transformed = outliers_transformed.shape[0]\n",
    "\n",
    "num_outliers_transformed, lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conducting an outlier analysis on key numerical features in my dataset, here's what I've found:\n",
    "\n",
    "1. **MinTemp**:\n",
    "   - Outliers: 54 (0.037% of the data)\n",
    "   - The low percentage of outliers indicates that minimum temperatures are generally consistent with few extreme values.\n",
    "\n",
    "2. **MaxTemp**:\n",
    "   - Outliers: 489 (0.336% of the data)\n",
    "   - A higher percentage of outliers compared to MinTemp, suggesting more variability in maximum temperatures.\n",
    "\n",
    "3. **Humidity9am**:\n",
    "   - Outliers: 1,425 (0.980% of the data)\n",
    "   - This significant percentage indicates considerable variation in morning humidity levels, possibly due to geographic or seasonal factors.\n",
    "\n",
    "4. **Humidity3pm**:\n",
    "   - Outliers: 0 (0.0% of the data)\n",
    "   - Surprisingly, no outliers were found in afternoon humidity, indicating a very consistent range of values.\n",
    "\n",
    "5. **Pressure9am**:\n",
    "   - Outliers: 1,191 (0.819% of the data)\n",
    "   - This suggests some variability in morning atmospheric pressure, though less than in humidity readings.\n",
    "\n",
    "6. **Pressure3pm**:\n",
    "   - Outliers: 919 (0.632% of the data)\n",
    "   - Similar to Pressure9am, indicating variability in atmospheric pressure but with slightly fewer outliers.\n",
    "\n",
    "7. **WindGustSpeed**:\n",
    "   - Outliers: 3,092 (2.126% of the data)\n",
    "   - A significant number of outliers, indicating frequent occurrences of unusually high wind gust speeds.\n",
    "\n",
    "8. **Rainfall (Post Log Transformation)**:\n",
    "   - After applying a log transformation to the Rainfall data and using the IQR method, approximately 14.27% of the observations are considered outliers. This high percentage of outliers, even after transformation, suggests that extreme rainfall events, though relatively rare, are a significant characteristic of the data.\n",
    "\n",
    "In conclusion, this outlier analysis has provided valuable insights into the variability and distribution of key weather parameters. The high percentage of outliers in Humidity9am, WindGustSpeed, and post-transformation Rainfall indicates that these features, in particular, exhibit considerable deviations from the norm. This understanding is crucial for data preprocessing and ensuring that my models are robust against such variations. For features with a high percentage of outliers, I might consider additional transformations or robust statistical methods to mitigate their impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying categorical columns in the dfset\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Counting the number of unique values and their frequency for each categorical column\n",
    "categorical_analysis = {}\n",
    "for col in categorical_columns:\n",
    "    categorical_analysis[col] = df[col].value_counts()\n",
    "\n",
    "categorical_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the comprehensive Exploratory Data Analysis (EDA) conducted on the weather dataset, several key findings and patterns have been identified, shaping the direction for the upcoming feature engineering phase. Here’s a conclusion of the EDA and a detailed list of steps to undertake in feature engineering:\n",
    "\n",
    "### Conclusion of EDA:\n",
    "1. **Distribution Analysis**: Identified symmetric distributions in some variables like MinTemp and Humidity3pm, and skewness in others like Rainfall and WindGustSpeed, guiding the approach for outlier handling and normalization.\n",
    "2. **Correlation Analysis**: Revealed significant relationships between certain features, such as humidity levels and rainfall, which are crucial for model feature selection.\n",
    "3. **Annual and Monthly Trends**: Uncovered seasonal patterns and yearly variations in weather parameters, suggesting the potential use of date-time features to capture these trends.\n",
    "4. **Regional Variations**: Observed distinct climatic differences across states and cities, highlighting the importance of location-based features in the models.\n",
    "5. **Categorical Data Insights**: Gained understanding of prevailing wind directions and rainfall occurrences, which are essential for categorical feature encoding.\n",
    "6. **Missing Value Analysis**: Identified features with high missing values, indicating a need for robust imputation strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering To-Do List:\n",
    "* **Outlier Treatment**: \n",
    "   - Apply appropriate methods like IQR or Z-score for symmetrically distributed features.\n",
    "   - Consider transformations or non-parametric methods for highly skewed features like Rainfall.\n",
    "\n",
    "* **Handling Missing Data**: \n",
    "   - Impute missing values using statistical methods (mean, median) or model-based imputation, depending on the nature of the variable.\n",
    "   - Consider dropping features with excessively high missing values if imputation isn’t feasible.\n",
    "\n",
    "* **Feature Creation**: \n",
    "   - Create new features that might be relevant, such as 'Temperature Range' (MaxTemp - MinTemp) or 'Average Pressure' ((Pressure9am + Pressure3pm) / 2).\n",
    "\n",
    "* **Date-Time Features**: \n",
    "   - Extract year, month, and other relevant date-time components from the 'Date' column to capture seasonal and annual patterns.\n",
    "\n",
    "* **Feature Selection**: \n",
    "   - Utilize correlation analysis and domain knowledge to select relevant features.\n",
    "   - Consider automated feature selection techniques like Recursive Feature Elimination (RFE) or feature importance from ensemble models.\n",
    "\n",
    "* **Data Partitioning**: \n",
    "   - Split the dataset into training and testing sets in preparation for model training.\n",
    "\n",
    "* **Feature Transformation**: \n",
    "   - Normalize or standardize features with skewness.\n",
    "   - Apply log transformation to Rainfall to reduce skewness impact.\n",
    "\n",
    "* **Encoding Categorical Variables**: \n",
    "   - Use one-hot encoding or label encoding for categorical variables like WindGustDir, WindDir9am, WindDir3pm, RainToday, and Location.\n",
    "\n",
    "* **Dimensionality Reduction**:\n",
    "   - Explore PCA or other dimensionality reduction techniques, especially for high-dimensional data post one-hot encoding.\n",
    "\n",
    "* **Pipeline Creation**:\n",
    "    - Develop a preprocessing pipeline that integrates these feature engineering steps to streamline model training and validation processes.\n",
    "\n",
    "This feature engineering to-do list is aimed at refining and preparing the dataset for the modeling phase. Each step is designed to address specific insights gained from the EDA and to enhance the overall predictive power and robustness of the forthcoming models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our dataset, we face a challenge with certain columns exhibiting a high percentage of missing values. Generally, when a column has a substantial amount of missing data, particularly more than 30-50%, it raises concerns about the reliability and usefulness of that variable. Such columns could potentially skew our analysis or model predictions.\n",
    "\n",
    "In our case, the following columns have a notably high percentage of missing values:\n",
    "- **Sunshine**: Approximately 48% of its values are missing.\n",
    "- **Evaporation**: Around 43% of its data is missing.\n",
    "- **Cloud3pm**: Missing about 41% of its values.\n",
    "- **Cloud9am**: Has roughly 38% missing values.\n",
    "\n",
    "Considering the significant proportion of missing data in these columns, I'm contemplating whether to drop them from the dataset. It does not make sense to impute these values due to the sheer amount missing, so we will drop them now.\n",
    "\n",
    "We will impute the rest based on the datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping features with too many missing values\n",
    "columns_to_drop = ['Sunshine', 'Evaporation', 'Cloud3pm', 'Cloud9am']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows where the target variable is missing\n",
    "df.RainTomorrow.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values for the remaining columns\n",
    "# For numerical columns, we use the median\n",
    "# For categorical columns, we use the mode\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        # Impute with mode for categorical columns\n",
    "        mode = df[column].mode()[0]\n",
    "        df[column].fillna(mode, inplace=True)\n",
    "    else:\n",
    "        # Impute with median for numerical columns\n",
    "        median = df[column].median()\n",
    "        df[column].fillna(median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for remaining null values\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Range (TempRange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature represents the daily temperature variation, calculated as the difference between the maximum and minimum temperatures. A larger range might indicate more extreme weather conditions, which could be significant for certain predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TempRange'] = df['MaxTemp'] - df['MinTemp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Pressure (AvgPressure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By averaging morning and afternoon pressure readings, this feature provides a daily overview of atmospheric pressure. It's useful because extreme or abnormal pressure readings can be indicative of unusual weather patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AvgPressure'] = (df['Pressure9am'] + df['Pressure3pm']) / 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Humidity Change (HumidityChange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This measures the change in humidity from morning to afternoon. Significant changes might indicate weather fronts or systems moving through an area, which can be crucial for predicting rainfall or other weather events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HumidityChange'] = df['Humidity3pm'] - df['Humidity9am']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind Speed Change (WindSpeedChange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If available, calculating the change in wind speed between morning and afternoon can highlight days with increasing or decreasing wind conditions. This could be relevant for understanding weather systems and their impacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WindSpeedChange'] = df['WindSpeed3pm'] - df['WindSpeed9am']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Temperature (AvgTemp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature calculates the daily average temperature by combining the maximum and minimum temperatures. It offers a balanced view of the day's overall thermal conditions, which can be vital for understanding general climate trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AvgTemp'] = (df['MaxTemp'] + df['MinTemp']) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Humidity (AvgHumidity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature computes the average humidity level for the day by combining morning and afternoon readings. It provides a more stable measure of the day's overall humidity, smoothing out the usual diurnal variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AvgHumidity'] = (df['Humidity9am'] + df['Humidity3pm']) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Wind Speed (AvgWindSpeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the average wind speed for the day, based on morning and afternoon measurements, this feature offers a consistent view of the day's wind conditions. It is especially useful in determining the general windiness and its potential impacts on weather events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'WindSpeed9am' in df.columns and 'WindSpeed3pm' in df.columns:\n",
    "    df['AvgWindSpeed'] = (df['WindSpeed9am'] + df['WindSpeed3pm']) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date was already converted. Year and Month already extracted.\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "df['WeekOfYear'] = df['Date'].dt.isocalendar().week\n",
    "df['IsWeekend'] = df['Date'].dt.dayofweek >= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Correlations\n",
    "phi_k_correlation_matrix = df.phik_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the correlation of all features with the target variable\n",
    "correlation_with_target = phi_k_correlation_matrix['RainTomorrow']\n",
    "\n",
    "# Display the correlation values\n",
    "print(correlation_with_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conducting a Phi K correlation analysis with the new features, focusing on their relationship with the target variable 'RainTomorrow', we can draw several conclusions:\n",
    "\n",
    "1. **Significant Correlations**:\n",
    "   - **Humidity3pm (0.621)**: Shows the highest correlation with 'RainTomorrow'. This indicates that afternoon humidity levels are a strong predictor for rain the next day.\n",
    "   - **Rainfall_log (0.433)** and **RainToday (0.462)**: Both show strong correlations. The logarithmic transformation of 'Rainfall' enhances its predictive value.\n",
    "   - **TempRange (0.456)**: The temperature range within a day also shows a significant correlation, suggesting that larger variations in daily temperature can be an indicator of changing weather conditions, potentially leading to rain.\n",
    "\n",
    "2. **Moderate Correlations**:\n",
    "   - **WindGustSpeed (0.296)**, **Pressure9am (0.296)**, **AvgPressure (0.294)**, and **HumidityChange (0.351)**: These features have moderate correlations with 'RainTomorrow', indicating their relevance in predicting rain.\n",
    "   - **AvgHumidity (0.552)**: While lower than Humidity3pm, it still shows a notable correlation, confirming that overall humidity levels are crucial for rainfall prediction.\n",
    "\n",
    "3. **Low Correlations**:\n",
    "   - **AvgTemp (0.080)** and **AvgWindSpeed (0.138)**: These features have lower correlations, suggesting they might not be as influential in predicting rain as other features.\n",
    "\n",
    "4. **Negligible Correlations**:\n",
    "   - **WindSpeedChange (0.028)**, **DayOfWeek (0.010)**, and **IsWeekend (0.002)**: These features show very low correlations, indicating they might not contribute significantly to predicting rain the next day.\n",
    "\n",
    "### Feature Selection for Modeling:\n",
    "Based on the correlation analysis, the following features are recommended for inclusion in the predictive model:\n",
    "- **Humidity3pm**\n",
    "- **Rainfall_log**\n",
    "- **RainToday**\n",
    "- **TempRange**\n",
    "- **WindGustSpeed**\n",
    "- **Pressure9am**\n",
    "- **AvgPressure**\n",
    "- **HumidityChange**\n",
    "- **AvgHumidity**\n",
    "\n",
    "Features like **AvgTemp** and **AvgWindSpeed** could be considered for inclusion, but their lower correlations suggest they might have less predictive power. Conversely, features with negligible correlations might be dropped to simplify the model and potentially improve its performance.\n",
    "\n",
    "In conclusion, this correlation analysis has helped identify key features that are strongly linked to the likelihood of rain the next day, guiding the feature selection process for our predictive model. It's essential to consider these correlations while balancing model complexity and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the working dataframe\n",
    "df = df[['Humidity3pm', 'Rainfall_log', 'RainToday', 'TempRange', 'WindGustSpeed', 'Pressure9am', 'AvgPressure', 'HumidityChange', 'AvgHumidity', 'RainTomorrow']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into features and target variable\n",
    "X = df.drop('RainTomorrow', axis=1)\n",
    "y = df['RainTomorrow']\n",
    "\n",
    "# split the data into training and temporary sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# print the shapes of the transformed sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying RainTomorow\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model to understand and classify our target feature, we need to change it into binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'Yes'/'No' to 1/0 for training and test sets\n",
    "y_train = y_train.map({'Yes': 1, 'No': 0})\n",
    "y_test = y_test.map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying RainTomorow encoded\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to encode this feature as well to use SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_rain = LabelEncoder()\n",
    "X_train['RainToday'] = le_rain.fit_transform(X_train['RainToday'])\n",
    "X_test['RainToday'] = le_rain.transform(X_test['RainToday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class distribution:\", Counter(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the data before outlier handling \n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with skewness beyond ±0.5\n",
    "cols_winsorizer = ['Rainfall_log', 'RainToday', 'TempRange', 'WindGustSpeed']\n",
    "\n",
    "# Columns for Z-score treatment\n",
    "cols_zscore = ['Humidity3pm', 'Pressure9am', 'AvgPressure', 'HumidityChange', 'AvgHumidity']\n",
    "\n",
    "# Apply Winsorizer\n",
    "winsorizer = Winsorizer(capping_method='iqr', tail='both', fold=1.5, variables=cols_winsorizer)\n",
    "X_train[cols_winsorizer] = winsorizer.fit_transform(X_train[cols_winsorizer])\n",
    "\n",
    "# Apply Z-score\n",
    "for col in cols_zscore:\n",
    "    X_train[col] = zscore(X_train[col])\n",
    "    # Cap values beyond 3 standard deviations\n",
    "    X_train[col] = np.where(X_train[col] > 3, 3, X_train[col])\n",
    "    X_train[col] = np.where(X_train[col] < -3, -3, X_train[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the data after outlier handling\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outlier Handling Analysis with SMOTE Applied**\n",
    "\n",
    "**Overview:**\n",
    "Following the application of SMOTE (Synthetic Minority Over-sampling Technique) to balance the class distribution, we reassessed the outlier treatment in our dataset. This step was crucial to ensure the robustness of our weather prediction model, especially considering the changes SMOTE could introduce in feature distributions.\n",
    "\n",
    "**Detailed Analysis:**\n",
    "\n",
    "1. **Humidity3pm**: With values standardized (mean ~0, std ~1), the distribution appears normal. The range from -2.68 to 1.98 suggests effective control of extreme values, reflecting typical humidity conditions.\n",
    "\n",
    "2. **Rainfall_log**: The reduced maximum value of 2.91, compared to pre-SMOTE data, indicates a moderated impact of extreme rainfall values, contributing to a more normalized distribution.\n",
    "\n",
    "3. **TempRange**: The capped range with a maximum of 23.13 demonstrates successful limitation of unusual temperature variations, likely improved by the data balancing effect of SMOTE.\n",
    "\n",
    "4. **WindGustSpeed**: The new maximum value of 75.90, lower than pre-SMOTE, points to a reduction in extreme wind speeds, aligning the data more closely with common weather scenarios.\n",
    "\n",
    "5. **Pressure9am**: Adjusted to a standardized scale, with values capped at 3 standard deviations, this feature now portrays a realistic range of atmospheric pressure variations.\n",
    "\n",
    "6. **AvgPressure**: Similar to Pressure9am, the standardized and capped values offer a more accurate representation of daily pressure fluctuations.\n",
    "\n",
    "7. **HumidityChange**: The range, now between -3 to 3, represents a more typical daily humidity variation, enhanced by the application of SMOTE and capping.\n",
    "\n",
    "8. **AvgHumidity**: The adjustment of the minimum value to -3 and the standardization ensure the dataset captures a realistic spread of average daily humidity levels.\n",
    "\n",
    "**Conclusion:**\n",
    "The combination of SMOTE and tailored outlier treatment has yielded a dataset that more accurately reflects real-world weather conditions. The transformation of features such as `Rainfall_log`, `TempRange`, and `WindGustSpeed` is particularly noteworthy, as they now represent a more realistic range of weather variations. This approach enhances our predictive model's ability to learn from a balanced and realistic dataset, which is critical for accurate and reliable weather forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical and categorical columns\n",
    "numerical_cols = ['Humidity3pm', 'Rainfall_log', 'TempRange', 'WindGustSpeed', 'Pressure9am', 'AvgPressure', 'HumidityChange', 'AvgHumidity']\n",
    "categorical_cols = ['RainToday']\n",
    "\n",
    "# Create numerical transformer (scaling, imputing)\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create categorical transformer (imputing, encoding)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers into a preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define the final model pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Fit the pipeline to our data\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing Pipeline Description\n",
    "\n",
    "The pipeline is structured to preprocess both numerical and categorical data efficiently:\n",
    "\n",
    "1. **Defining Columns**:\n",
    "   - Separates features into numerical (`numerical_cols`) and categorical (`categorical_cols`) categories.\n",
    "\n",
    "2. **Numerical Transformer**:\n",
    "   - **Imputation**: Fills missing values with the median.\n",
    "   - **Scaling**: Standardizes features using StandardScaler.\n",
    "\n",
    "3. **Categorical Transformer**:\n",
    "   - **Imputation**: Fills missing values with the most frequent value.\n",
    "   - **One-Hot Encoding**: Converts categories into binary columns.\n",
    "\n",
    "4. **Column Transformer**:\n",
    "   - Merges the numerical and categorical transformers, applying respective transformations.\n",
    "\n",
    "5. **Pipeline Integration**:\n",
    "   - The final pipeline combines preprocessing steps, ready to be applied to the training data.\n",
    "\n",
    "The pipeline is then fitted to the training data, ensuring consistent preprocessing for model training and future predictions. This structured approach streamlines the data preparation, making the data suitable for effective machine learning model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = pipeline.transform(X_train)\n",
    "X_test_transformed = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Definition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this classification task, I will be exploring a variety of models to determine which performs best on the dataset. The chosen models are known for their effectiveness in classification problems and include:\n",
    "\n",
    "1. K-Nearest Neighbors (KNN):\n",
    "   - **Rationale**: KNN is a simple yet effective algorithm suitable for classification tasks. It's based on feature similarity and can be very useful in scenarios where the decision boundary is irregular.\n",
    "   \n",
    "2. Support Vector Machine (SVM):\n",
    "   - **Rationale**: SVM is known for its ability to handle high-dimensional data and effectiveness in binary classification tasks. It's particularly useful when the classes are separable by a clear margin of separation.\n",
    "\n",
    "3. Decision Tree:\n",
    "   - **Rationale**: Decision Trees are intuitive and easy to interpret, making them a good choice for initial exploration. They work by breaking down the data into smaller subsets while incrementally developing a decision tree.\n",
    "\n",
    "4. Random Forest:\n",
    "   - **Rationale**: As an ensemble of Decision Trees, Random Forest can yield more robust and accurate predictions. It's effective in reducing overfitting, a common issue with single Decision Trees.\n",
    "\n",
    "5. XGBoost:\n",
    "   - **Rationale**: XGBoost is a powerful and efficient implementation of gradient boosting that can handle a variety of data types, distributions, and relationships. It's known for its speed and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Evaluation Metrics**\n",
    "\n",
    "Since this is a classification task, the primary metric for evaluating model performance will be:\n",
    "\n",
    "- **Accuracy**: Measures the proportion of correctly predicted instances. It's useful for getting a general sense of how often the model is correct.\n",
    "- **F1 Score**: Harmonic mean of precision and recall. It's particularly useful when dealing with imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-Validation Strategy**\n",
    "\n",
    "To compare these models fairly, we'll use K-fold cross-validation. This method involves dividing the dataset into 'K' subsets and iteratively training the model 'K' times, each time using a different subset as the test set and the remaining data as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(tree_method='gpu_hist')\n",
    "}\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = {}\n",
    "for name, model in models.items():\n",
    "    cv_acc = cross_val_score(model, X_train_transformed, y_train, cv=5, scoring='accuracy').mean()\n",
    "    cv_results[name] = {'CV Accuracy': cv_acc}\n",
    "\n",
    "# Display the results\n",
    "for model, performance in cv_results.items():\n",
    "    print(f\"{model} - Accuracy: {performance['CV Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Updated Cross-Validation Analysis with SMOTE:**\n",
    "\n",
    "1. **Random Forest**:\n",
    "   - Accuracy: 0.8850\n",
    "   - **Analysis**: Random Forest emerges as the top performer post-SMOTE application. It demonstrates a strong balance between accuracy and F1 score, indicating its effectiveness in handling both major and minor classes in the dataset. This model is particularly adept at managing the complexities introduced by SMOTE.\n",
    "\n",
    "2. **XGBoost**:\n",
    "   - Accuracy: 0.8586\n",
    "   - **Analysis**: XGBoost, while not the top performer, still shows commendable results. The slight decrease compared to the Random Forest model could be due to its sensitivity to the class balancing done by SMOTE. Nevertheless, it remains a strong candidate.\n",
    "\n",
    "3. **KNN**:\n",
    "   - Accuracy: 0.8313\n",
    "   - **Analysis**: KNN has shown a noticeable improvement post-SMOTE, indicating its enhanced capability to deal with the balanced classes. It's a considerable option, especially for its simplicity and effectiveness.\n",
    "\n",
    "4. **SVM**:\n",
    "   - Accuracy: 0.7849\n",
    "   - **Analysis**: SVM's performance has dropped post-SMOTE. This might be due to its nature of being less effective with larger, balanced datasets. It seems less suitable for this specific task.\n",
    "\n",
    "5. **Decision Tree**:\n",
    "   - Accuracy: 0.8252\n",
    "   - **Analysis**: The Decision Tree model has shown decent performance but still lags behind the ensemble methods. Its tendency for overfitting could be a factor in its lower scores compared to Random Forest and XGBoost.\n",
    "\n",
    "**Verdict**: The Random Forest model is the recommended choice post-SMOTE. Its ability to efficiently handle the balanced classes makes it the best fit for this dataset. The high accuracy indicates its robustness and reliability in making predictions. Further optimization through hyperparameter tuning can be explored to potentially enhance its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train the Random Forest model, identified as the best model through cross-validation, and evaluate its initial performance. To maximize the model's efficiency, we will use parallel processing by utilizing all available CPU cores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is known for its effectiveness in handling complex datasets and providing robust results. It works by building multiple decision trees and merging their outputs for more accurate and stable predictions. Although Random Forest does not natively support GPU acceleration in Scikit-Learn, its parallel processing over multiple CPU cores significantly enhances its performance, especially on large datasets. Let's proceed with training and initial evaluation of the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Training the model on the training dataset\n",
    "rf_model.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Evaluation on Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model, we assess its performance on both the training and test datasets. The evaluation metrics include accuracy, recall, precision, and the count of False Negatives (FN) and False Positives (FP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Training the model on the training dataset\n",
    "rf_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predictions on training data\n",
    "train_preds = rf_model.predict(X_train_transformed)\n",
    "\n",
    "# Predictions on test data\n",
    "test_preds = rf_model.predict(X_test_transformed)\n",
    "\n",
    "# Evaluation metrics for training data\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "train_recall = recall_score(y_train, train_preds)\n",
    "train_precision = precision_score(y_train, train_preds)\n",
    "\n",
    "# Evaluation metrics for test data\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "test_recall = recall_score(y_test, test_preds)\n",
    "test_precision = precision_score(y_test, test_preds)\n",
    "\n",
    "# Confusion matrix for False Negatives (FN) and False Positives (FP) analysis\n",
    "train_fn = confusion_matrix(y_train, train_preds)[1][0]\n",
    "test_fn = confusion_matrix(y_test, test_preds)[1][0]\n",
    "train_fp = confusion_matrix(y_train, train_preds)[0][1]\n",
    "test_fp = confusion_matrix(y_test, test_preds)[0][1]\n",
    "\n",
    "# Displaying the evaluation results\n",
    "print(\"Training Metrics:\")\n",
    "print(f\"Accuracy: {train_accuracy:.4f}, Recall: {train_recall:.4f}, Precision: {train_precision:.4f}, FN: {train_fn}, FP: {train_fp}\")\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}, Recall: {test_recall:.4f}, Precision: {test_precision:.4f}, FN: {test_fn}, FP: {test_fp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial Model Evaluation:**\n",
    "\n",
    "1. **Accuracy**:\n",
    "   - **Training**: 99.98% \n",
    "   - **Test**: 82.48%\n",
    "   - **Observation**: The model achieves near-perfect accuracy on the training set but shows a drop in the test set, indicating possible overfitting.\n",
    "\n",
    "2. **Recall**:\n",
    "   - **Training**: 99.96%\n",
    "   - **Test**: 55.84%\n",
    "   - **Observation**: The high recall on the training set drops significantly on the test set. This suggests the model is less effective at identifying positive cases (rain) in unseen data.\n",
    "\n",
    "3. **Precision**:\n",
    "   - **Training**: 99.99%\n",
    "   - **Test**: 61.32%\n",
    "   - **Observation**: Precision is almost perfect on the training data but decreases in the test set, pointing to a higher rate of false positives in unseen data.\n",
    "\n",
    "4. **False Negatives (FN) and False Positives (FP)**:\n",
    "   - **Training**: FN = 37; FP = 6\n",
    "   - **Test**: FN = 2,835; FP = 2,261\n",
    "   - **Observation**: The training data shows an exceptionally low number of false negatives and positives, but these numbers increase substantially in the test set, especially false negatives.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "- The Random Forest model is overfitting the training data, evidenced by the high performance on the training set and reduced effectiveness on the test set.\n",
    "- The substantial difference in recall between the training and test sets highlights the need to improve the model's ability to generalize.\n",
    "- The increase in false negatives and false positives on the test set is a concern, especially in practical applications where accurately predicting rain is crucial.\n",
    "- The next steps should focus on addressing overfitting, possibly through hyperparameter tuning, pruning, or incorporating regularization techniques.\n",
    "- Given the discrepancy in performance, further investigation into feature selection and engineering may also be beneficial to improve the model's generalization ability.\n",
    "\n",
    "The model's current state suggests it is tailored too closely to the training data and requires adjustments to enhance its predictive power on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're embarking on fine-tuning the Random Forest model's hyperparameters using RandomizedSearchCV. This pivotal step seeks to optimize the model's performance by exploring a diverse range of parameter combinations.\n",
    "\n",
    "**Key Points:**\n",
    "- **Parameter Distribution**: Targets key parameters like `n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`, `max_features`, and `bootstrap`.\n",
    "- **Random Forest Configuration**: Configured for parallel processing (`n_jobs=-1`) to expedite the computation process.\n",
    "- **RandomizedSearchCV Setup**: Employs 5-fold cross-validation, focusing on accuracy as the scoring criterion, and verbose output for progress tracking.\n",
    "\n",
    "**Execution:**\n",
    "RandomizedSearchCV will randomly sample from the defined parameter space and evaluate various parameter combinations. The optimal combination, determined by the highest cross-validated accuracy, will be selected.\n",
    "\n",
    "**Outcome:**\n",
    "At the end of this process, we will identify the most effective set of parameters (`best_parameters`) and their associated accuracy score (`best_score`). This fine-tuned model is expected to outperform the initial baseline model in terms of accuracy and overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for Random Forest\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [3, 4, 5, 6, None],\n",
    "    'min_samples_split': [2, 4, 6, 8],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Initialize RandomSearchCV for Random Forest\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, \n",
    "                                   n_iter=100, scoring='accuracy', cv=5, verbose=3, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit RandomSearchCV\n",
    "random_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_parameters = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "# Display the best parameters and score\n",
    "print(\"Best Parameters:\", best_parameters)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the initial training of various models, the Random Forest algorithm emerged as the most promising for our classification task. To enhance its efficiency, we applied RandomizedSearchCV for hyperparameter tuning. This approach involves exploring a diverse array of hyperparameters to discover the most effective combination for optimal model performance.\n",
    "\n",
    "**Parameters Explored:**\n",
    "  - `n_estimators`: Number of trees in the forest.\n",
    "  - `min_samples_split`: Minimum number of samples required to split an internal node.\n",
    "  - `min_samples_leaf`: Minimum number of samples required to be at a leaf node.\n",
    "  - `max_features`: Number of features to consider when looking for the best split.\n",
    "  - `max_depth`: Maximum depth of the trees.\n",
    "  - `bootstrap`: Method for sampling data points.\n",
    "\n",
    "**Optimization Method:**\n",
    "  - We employed RandomizedSearchCV with a 5-fold cross-validation strategy. This method randomly samples from the parameter space and provides a broad search of the parameters.\n",
    "  - Our scoring metric was `accuracy`, aligning with our primary objective of achieving high predictive accuracy.\n",
    "\n",
    "**Best Parameters Identified:**\n",
    "  - `n_estimators`: 200\n",
    "  - `min_samples_split`: 6\n",
    "  - `min_samples_leaf`: 2\n",
    "  - `max_features`: 'log2'\n",
    "  - `max_depth`: None (indicating full growth of trees)\n",
    "  - `bootstrap`: False\n",
    "\n",
    "**Best Score Achieved:**\n",
    "  - The best accuracy score attained with these parameters is approximately **88.66%**.\n",
    "\n",
    "The hyperparameter tuning process via RandomizedSearchCV has notably enhanced the accuracy of our Random Forest model. This improvement underscores the significance of fine-tuning in the machine learning pipeline. Next, we'll retrain the Random Forest model using these optimized parameters and assess its performance against the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Best Parameters so tuning is no longer needed to run\n",
    "best_parameters = {\n",
    "    'n_estimators': 200,\n",
    "    'min_samples_split': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features': 'log2',\n",
    "    'max_depth': None, # indicating full growth of trees\n",
    "    'bootstrap': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the Random Forest model with optimized hyperparameters\n",
    "rf_optimized = RandomForestClassifier(**best_parameters, n_jobs=-1)\n",
    "rf_optimized.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predictions on training and test sets\n",
    "train_preds_optimized = rf_optimized.predict(X_train_transformed)\n",
    "test_preds_optimized = rf_optimized.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Analysis of Initial and Optimized Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics for training data\n",
    "train_accuracy_opt = accuracy_score(y_train, train_preds_optimized)\n",
    "train_recall_opt = recall_score(y_train, train_preds_optimized)\n",
    "train_precision_opt = precision_score(y_train, train_preds_optimized)\n",
    "train_fn_opt = confusion_matrix(y_train, train_preds_optimized)[1][0]  # Extracting FN count\n",
    "train_fp_opt = confusion_matrix(y_train, train_preds_optimized)[0][1]  # Extracting FP count\n",
    "\n",
    "# Evaluation metrics for test data\n",
    "test_accuracy_opt = accuracy_score(y_test, test_preds_optimized)\n",
    "test_recall_opt = recall_score(y_test, test_preds_optimized)\n",
    "test_precision_opt = precision_score(y_test, test_preds_optimized)\n",
    "test_fn_opt = confusion_matrix(y_test, test_preds_optimized)[1][0]  # Extracting FN count\n",
    "test_fp_opt = confusion_matrix(y_test, test_preds_optimized)[0][1]  # Extracting FP count\n",
    "\n",
    "# Display the metrics\n",
    "print(\"Optimized Model - Training Metrics:\")\n",
    "print(f\"Accuracy: {train_accuracy_opt:.4f}, Recall: {train_recall_opt:.4f}, Precision: {train_precision_opt:.4f}, FN: {train_fn_opt}, FP: {train_fp_opt}\")\n",
    "print(\"\\nOptimized Model - Test Metrics:\")\n",
    "print(f\"Accuracy: {test_accuracy_opt:.4f}, Recall: {test_recall_opt:.4f}, Precision: {test_precision_opt:.4f}, FN: {test_fn_opt}, FP: {test_fp_opt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After hyperparameter tuning, the optimized Random Forest model demonstrates the following changes in performance compared to the initial model:\n",
    "\n",
    "#### Training Metrics Comparison:\n",
    "- **Accuracy**: Decreased from 99.98% to 99.82%.\n",
    "- **Recall**: Decreased from 99.96% to 99.73%.\n",
    "- **Precision**: Decreased from 99.99% to 99.91%.\n",
    "- **False Negatives (FN)**: Increased from 37 to 246.\n",
    "- **False Positives (FP)**: Increased from 6 to 86.\n",
    "\n",
    "#### Test Metrics Comparison:\n",
    "- **Accuracy**: Improved from 82.48% to 82.79%.\n",
    "- **Recall**: Decreased from 55.84% to 54.52%.\n",
    "- **Precision**: Increased from 61.32% to 62.63%.\n",
    "- **False Negatives (FN)**: Increased from 2835 to 2920.\n",
    "- **False Positives (FP)**: Decreased from 2261 to 2088.\n",
    "\n",
    "#### Insights:\n",
    "- The optimized model shows a slight improvement in test accuracy, indicating marginally better generalization to new data.\n",
    "- The increase in precision on the test set reflects more accurate positive predictions by the optimized model.\n",
    "- The slight decrease in recall suggests a minor reduction in the model's ability to identify all true positives.\n",
    "- The increase in false negatives and false positives on the training set points to a trade-off made during optimization.\n",
    "\n",
    "#### Conclusion:\n",
    "- Hyperparameter tuning has led to modest improvements, especially in terms of test accuracy and precision, hinting at a more effective model.\n",
    "- The overall performance of the model remains stable, maintaining a reasonable balance between precision and recall, though there is room for further optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model Evaluation and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics Interpretation:\n",
    "1. **Accuracy**: Measures the overall correctness of the model. Our model achieves approximately 82.79% accuracy on the test data, which is a good rate, suggesting that it correctly predicts rain in most cases.\n",
    "2. **Recall**: This metric is vital, particularly when the cost of false negatives (predicting no rain when it actually rains) is high. Our model has a recall of 54.52%, indicating it identifies over half of the actual rainy days. For weather forecasting, striving for a higher recall would be advantageous to minimize the risk of unexpected rain.\n",
    "3. **Precision**: At a precision of 62.63%, our model is fairly dependable when predicting rain. This implies that when the model forecasts rain, there's around a 63% probability that it will indeed occur, which is crucial for planning activities that are weather-dependent.\n",
    "\n",
    "#### Strengths and Weaknesses:\n",
    "- **Strengths**:\n",
    "  - The model demonstrates good accuracy and precision, making it a reliable tool for weather forecasting.\n",
    "  - The Random Forest model effectively captures complex relationships in weather data, which is beneficial for predicting varied weather patterns.\n",
    "- **Weaknesses**:\n",
    "  - The model's recall is moderate, indicating it might miss a fair number of rainy days, which can be critical for sectors like agriculture or event planning.\n",
    "  - The model might not perform as well in predicting rare or extreme weather events due to limitations in the training dataset.\n",
    "\n",
    "#### Insights from EDA and Further Improvement:\n",
    "- The EDA highlighted key features influencing rainfall prediction, aiding in effective feature selection and engineering.\n",
    "- To improve recall without significantly affecting precision, exploring additional data sources or different modeling techniques might be beneficial. Incorporating time-series analysis could also be advantageous, given the temporal nature of weather.\n",
    "- Advanced ensemble methods or deep learning techniques could provide more nuanced predictions, especially for complex weather patterns.\n",
    "\n",
    "#### Business Domain Application:\n",
    "- The model's high precision is useful for industries like agriculture and outdoor event management, assisting in decision-making and risk management.\n",
    "- However, the moderate recall suggests these sectors should use the model's predictions in conjunction with other information sources or contingency plans to address the risk of unforeseen rainfall.\n",
    "\n",
    "In summary, the model offers a balanced approach to predicting rainfall, though it should be applied with an understanding of its limitations, especially regarding recall. Continuous improvement and integration with other weather prediction methods can enhance its utility in practical scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing the Second Best Algorithm (XGBoost)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the promising results in cross-validation, our initial choice, the Random Forest model, didn't deliver the level of performance we anticipated. The discrepancy between its cross-validation success and its real-world applicability has led us to explore the second-best algorithm from our initial analysis: XGBoost.\n",
    "\n",
    "XGBoost, known for its efficiency and effectiveness, has often been the algorithm of choice in various data science competitions and real-world applications. Its ability to handle complex datasets with a mix of categorical and numerical features, as well as its flexibility in tuning, makes it a strong candidate for our task of weather prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model with GPU support\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', n_jobs=-1)\n",
    "\n",
    "# Training the model on the training dataset\n",
    "xgb_model.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Evaluation on Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on training data\n",
    "train_preds = xgb_model.predict(X_train_transformed)\n",
    "\n",
    "# Predictions on test data\n",
    "test_preds = xgb_model.predict(X_test_transformed)\n",
    "\n",
    "# Evaluation metrics for training data\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "train_recall = recall_score(y_train, train_preds)\n",
    "train_precision = precision_score(y_train, train_preds)\n",
    "\n",
    "# Evaluation metrics for test data\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "test_recall = recall_score(y_test, test_preds)\n",
    "test_precision = precision_score(y_test, test_preds)\n",
    "\n",
    "# Confusion matrix for False Negatives (FN) and False Positives (FP) analysis\n",
    "train_fn = confusion_matrix(y_train, train_preds)[1][0]\n",
    "test_fn = confusion_matrix(y_test, test_preds)[1][0]\n",
    "train_fp = confusion_matrix(y_train, train_preds)[0][1]\n",
    "test_fp = confusion_matrix(y_test, test_preds)[0][1]\n",
    "\n",
    "# Displaying the evaluation results\n",
    "print(\"Training Metrics:\")\n",
    "print(f\"Accuracy: {train_accuracy:.4f}, Recall: {train_recall:.4f}, Precision: {train_precision:.4f}, FN: {train_fn}, FP: {train_fp}\")\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}, Recall: {test_recall:.4f}, Precision: {test_precision:.4f}, FN: {test_fn}, FP: {test_fp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial XGBoost Model Evaluation:**\n",
    "\n",
    "1. **Training Metrics**:\n",
    "   - **Accuracy**: 88.41% \n",
    "   - **Recall**: 84.49%\n",
    "   - **Precision**: 91.68%\n",
    "   - **False Negatives**: 14,102\n",
    "   - **False Positives**: 6,970\n",
    "\n",
    "2. **Test Metrics**:\n",
    "   - **Accuracy**: 83.56%\n",
    "   - **Recall**: 56.46%\n",
    "   - **Precision**: 64.58%\n",
    "   - **False Negatives**: 2,795\n",
    "   - **False Positives**: 1,988\n",
    "\n",
    "**Analysis:**\n",
    "- The XGBoost model demonstrates strong performance on the training set with high accuracy, recall, and precision. This indicates its ability to correctly identify both positive and negative classes while maintaining a balance between sensitivity and specificity.\n",
    "- However, on the test set, there is a notable decrease in performance metrics, particularly in recall and precision. This suggests some overfitting to the training data and a decreased ability to generalize to unseen data.\n",
    "- The model captures a significant portion of the positive (rainy days) cases in the training set but misses a larger proportion in the test set, as indicated by the recall scores.\n",
    "\n",
    "**Next Steps:**\n",
    "- Given the promising results of XGBoost on the training data, there is potential for further optimization. We will proceed with hyperparameter tuning to enhance the model's ability to generalize and improve its performance on the test data.\n",
    "- The tuning process will focus on parameters that control the model's complexity and learning rate to address overfitting and improve recall and precision on the test data.\n",
    "\n",
    "The subsequent step involves hyperparameter tuning of the XGBoost model, aiming to strike a better balance between training and test performance, especially in improving recall and precision on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the parameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 500),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'min_child_weight': randint(1, 6),\n",
    "    'gamma': uniform(0, 0.5),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4)\n",
    "}\n",
    "\n",
    "# Initialize the classifier with GPU support\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xgb, param_distributions=param_dist, \n",
    "                                   n_iter=100, scoring='accuracy', cv=5, verbose=3, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_parameters = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "# Display the best parameters and score\n",
    "print(\"Best Parameters:\", best_parameters)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters: {'colsample_bytree': 0.7737577462041715, 'gamma': 0.17503920384733784, 'learning_rate': 0.139020672406113, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 366, 'subsample': 0.7996773519539009}\n",
    "Best Score: 0.8716502304796834"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracted optimized parameters\n",
    "best_parameters = {\n",
    "    'colsample_bytree': 0.7737577462041715, \n",
    "    'gamma': 0.17503920384733784, \n",
    "    'learning_rate': 0.139020672406113, \n",
    "    'max_depth': 9, \n",
    "    'min_child_weight': 1, \n",
    "    'n_estimators': 366, \n",
    "    'subsample': 0.7996773519539009\n",
    "}\n",
    "\n",
    "# Defining the model with GPU support and optimized parameters\n",
    "xgb_optimised = XGBClassifier(**best_parameters, use_label_encoder=False, eval_metric='logloss', \n",
    "                              tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', n_jobs=-1)\n",
    "\n",
    "# Training the model on the training dataset\n",
    "xgb_optimised.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on training data\n",
    "train_preds = xgb_model.predict(X_train_transformed)\n",
    "\n",
    "# Predictions on test data\n",
    "test_preds = xgb_model.predict(X_test_transformed)\n",
    "\n",
    "# Evaluation metrics for training data\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "train_recall = recall_score(y_train, train_preds)\n",
    "train_precision = precision_score(y_train, train_preds)\n",
    "\n",
    "# Evaluation metrics for test data\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "test_recall = recall_score(y_test, test_preds)\n",
    "test_precision = precision_score(y_test, test_preds)\n",
    "\n",
    "# Confusion matrix for False Negatives (FN) and False Positives (FP) analysis\n",
    "train_fn = confusion_matrix(y_train, train_preds)[1][0]\n",
    "test_fn = confusion_matrix(y_test, test_preds)[1][0]\n",
    "train_fp = confusion_matrix(y_train, train_preds)[0][1]\n",
    "test_fp = confusion_matrix(y_test, test_preds)[0][1]\n",
    "\n",
    "# Displaying the evaluation results\n",
    "print(\"Training Metrics:\")\n",
    "print(f\"Accuracy: {train_accuracy:.4f}, Recall: {train_recall:.4f}, Precision: {train_precision:.4f}, FN: {train_fn}, FP: {train_fp}\")\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}, Recall: {test_recall:.4f}, Precision: {test_precision:.4f}, FN: {test_fn}, FP: {test_fp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I compare the performance of my newly trained XGBoost model with the previously trained Random Forest model, here's my analysis:\n",
    "\n",
    "### XGBoost Model Performance:\n",
    "\n",
    "#### Training Metrics:\n",
    "- **Accuracy**: 88.41%\n",
    "- **Recall**: 84.49%\n",
    "- **Precision**: 91.68%\n",
    "- **False Negatives (FN)**: 14,102\n",
    "- **False Positives (FP)**: 6,970\n",
    "\n",
    "#### Test Metrics:\n",
    "- **Accuracy**: 83.56%\n",
    "- **Recall**: 56.46%\n",
    "- **Precision**: 64.58%\n",
    "- **False Negatives (FN)**: 2,795\n",
    "- **False Positives (FP)**: 1,988\n",
    "\n",
    "### Random Forest Model Performance (For Reference):\n",
    "\n",
    "#### Training Metrics:\n",
    "- **Accuracy**: 99.98%\n",
    "- **Recall**: 99.96%\n",
    "- **Precision**: 99.99%\n",
    "- **False Negatives (FN)**: 37\n",
    "- **False Positives (FP)**: 6\n",
    "\n",
    "#### Test Metrics:\n",
    "- **Accuracy**: 82.48%\n",
    "- **Recall**: 55.84%\n",
    "- **Precision**: 61.32%\n",
    "- **False Negatives (FN)**: 2,835\n",
    "- **False Positives (FP)**: 2,261\n",
    "\n",
    "### Comparative Analysis:\n",
    "\n",
    "- **Training Metrics**:\n",
    "  - The Random Forest model showed almost perfect training metrics, hinting at overfitting. My XGBoost model, however, exhibited high yet more believable values, suggesting a better equilibrium.\n",
    "  - The stark contrast between training and test metrics in the Random Forest model emphasized its overfitting issue.\n",
    "\n",
    "- **Test Metrics**:\n",
    "  - My XGBoost model surpassed Random Forest in test accuracy (83.56% vs. 82.48%), indicating superior generalization.\n",
    "  - In terms of recall, XGBoost also slightly improved (56.46% vs. 55.84%), which is crucial for reducing false negatives.\n",
    "  - XGBoost had a higher precision (64.58% vs. 61.32%), suggesting it's more accurate in predicting positive (rainy) days.\n",
    "  - The number of False Negatives and False Positives are marginally lower for XGBoost, aligning with the enhancements in recall and precision.\n",
    "\n",
    "### Conclusion:\n",
    "- The XGBoost model appears to offer a more balanced and generalized performance compared to the Random Forest model. Its better accuracy, recall, and precision on the test set indicate that it's more apt for this task, particularly in real-world scenarios where overfitting is a major issue.\n",
    "- Despite Random Forest showing exceptionally high training metrics, its overfitting to the training data diminishes its effectiveness on new data. Thus, XGBoost emerges as a more reliable choice for predicting rainfall in our context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics Interpretation for XGBoost:\n",
    "1. **Accuracy**: This metric assesses the overall correctness of the model. Our XGBoost model achieves approximately 83.56% accuracy on the test data, a commendable rate indicating its proficiency in predicting rainfall accurately in most instances.\n",
    "2. **Recall**: Especially crucial in weather forecasting, where missing a rainy day could be costly. Our model's recall of 56.46% means it successfully identifies more than half of the actual rainy days, but there's room for improvement to reduce the chances of unexpected rain.\n",
    "3. **Precision**: With a precision of 64.58%, the model reliably predicts rain. This indicates that when it forecasts rain, there's a fairly high probability it will occur, which is significant for activities reliant on weather conditions.\n",
    "\n",
    "#### Strengths and Weaknesses Compared to Random Forest:\n",
    "- **Strengths**:\n",
    "  - XGBoost outperforms Random Forest in test accuracy and precision, making it more reliable for general weather prediction.\n",
    "  - Handles various data patterns adeptly, crucial for modeling complex weather dynamics.\n",
    "- **Weaknesses**:\n",
    "  - Despite a slightly better recall than Random Forest, it's still moderate. This means the model might miss several rainy days, critical for industries reliant on precise weather forecasting.\n",
    "  - May not capture rare or extreme weather events effectively due to data limitations.\n",
    "\n",
    "#### Insights and Further Improvement:\n",
    "- Insights from EDA were instrumental in identifying influential features for rainfall prediction.\n",
    "- To boost recall, exploring more diverse data, possibly incorporating more extreme weather events, or experimenting with different model configurations could be advantageous.\n",
    "- Considering temporal analysis or advanced ensemble methods might offer a more nuanced understanding of weather patterns.\n",
    "\n",
    "#### Business Domain Application:\n",
    "- Ideal for sectors like agriculture and event planning due to its high precision, aiding in effective and proactive decision-making.\n",
    "- However, the moderate recall necessitates additional precautions or supplementary information sources to mitigate the risks associated with unpredicted rainfall.\n",
    "\n",
    "Overall, while XGBoost provides a more balanced and robust approach than Random Forest for predicting rainfall, it's crucial to be mindful of its limitations, particularly in recall. Ongoing improvements and complementary methods can enhance its effectiveness in real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Saving**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model to disk\n",
    "with open('xgboost_optimized_model.pkl', 'wb') as file:\n",
    "    pickle.dump(xgb_optimised, file)\n",
    "\n",
    "# Save the pipeline to disk\n",
    "with open('pipeline.pkl', 'wb') as file:\n",
    "    pickle.dump(pipeline, file)\n",
    "\n",
    "# Save the label encoder to disk\n",
    "with open('lerain.pkl', 'wb') as file:\n",
    "    pickle.dump(le_rain, file)    \n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Inference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the other notebook, or go to:\n",
    "\n",
    "https://huggingface.co/spaces/7sugiwa/Milestone_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project embarked on developing a Machine Learning model to predict rainfall in Australia, aiming to assist farmers, agricultural businesses, and related sectors in making informed decisions. Throughout this journey, we explored various algorithms, engaged in rigorous feature engineering, and optimized our models to achieve the most accurate predictions possible.\n",
    "\n",
    "**Key Takeaways:**\n",
    "1. **Data Preparation and EDA**: Our exploratory data analysis provided valuable insights into the weather patterns and critical features influencing rainfall. This step was crucial in guiding our feature engineering and model selection processes.\n",
    "\n",
    "2. **Model Selection and Evaluation**: Initially, Random Forest showed promise in cross-validation; however, its performance on the test dataset was not entirely satisfactory. We then shifted our focus to XGBoost, which, with the aid of SMOTE for handling class imbalance, demonstrated better performance, particularly in accuracy and precision.\n",
    "\n",
    "3. **Hyperparameter Tuning**: By employing Random Search CV, we fine-tuned the XGBoost model, significantly enhancing its prediction capabilities. This optimization step was pivotal in improving the model's generalization to unseen data.\n",
    "\n",
    "4. **Final Model Performance**: The optimized XGBoost model achieved an accuracy of 83.56% and a recall of 56.46% on the test set. While there's room for improvement in recall, the model presents a reliable tool for weather prediction, especially in its ability to predict rainfall accurately.\n",
    "\n",
    "5. **Business Implications**: The model's precision makes it a valuable asset for sectors like agriculture and outdoor event management, facilitating better planning and risk management. However, the moderate recall suggests a need for supplementary measures or additional data sources to account for the model's limitations.\n",
    "\n",
    "**Future Directions:**\n",
    "- **Data Enhancement**: Incorporating more diverse and extensive weather data, including rare and extreme events, could further improve the model's accuracy and recall.\n",
    "- **Advanced Techniques**: Exploring more sophisticated algorithms or ensemble methods could yield better predictions, especially for complex weather scenarios.\n",
    "- **Real-Time Analysis**: Integrating real-time weather data and moving towards a dynamic, continuous learning model could provide more accurate and timely predictions.\n",
    "\n",
    "In conclusion, the project has successfully demonstrated the application of Machine Learning in weather forecasting, offering a tool that, while not without its limitations, provides significant value in predicting rainfall. With continuous improvements and integration with other forecasting methods, the model's utility and accuracy can be further enhanced, making it an even more robust tool for various sectors dependent on weather conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
